{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from imageio import imread\n",
    "from collections import namedtuple\n",
    "from sklearn.utils import resample\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random generator seed for reproduction\n",
    "np.random.seed(77)\n",
    "tf.random.set_seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the dataset basepath \n",
    "basepath = '/home/thalles/Documents/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(folder):\n",
    "    return glob.glob(basepath + folder + '/0/*.png') + glob.glob('/home/thalles/Documents/datasets/' + folder + '/1/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the training examples\n",
    "training_files = get_filenames('train')\n",
    "np.random.shuffle(training_files)\n",
    "print(\"Number of training examples:\", len(training_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the validation examples\n",
    "val_files = get_filenames('val')\n",
    "np.random.shuffle(val_files)\n",
    "print(\"Number of validation examples:\", len(val_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the test examples\n",
    "test_files = get_filenames('test')\n",
    "np.random.shuffle(test_files)\n",
    "print(\"Number of testing examples:\", len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some of the slide patches\n",
    "fig, axs = plt.subplots(nrows=5, ncols=5, constrained_layout=False)\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    img = cv2.imread(training_files[i], 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def get_tf_feature(image_np, label):\n",
    "    img_raw = image_np.tostring()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                        'height': _int64_feature(image_np.shape[0]),\n",
    "                        'width': _int64_feature(image_np.shape[1]),\n",
    "                        'depth': _int64_feature(image_np.shape[2]),\n",
    "                        'image_raw': _bytes_feature(img_raw),\n",
    "                        'label': _int64_feature(label)}))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFRecordManager:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.file = tf.io.TFRecordWriter(self.filename) \n",
    "        return self.file\n",
    "    \n",
    "    def __exit__(self, exception_type, exception_value, traceback):\n",
    "        if exception_type:\n",
    "            print(exception_type, exception_value)\n",
    "        if self.file:\n",
    "            self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the output dataset file\n",
    "DATASET_DIR= \"./tfrecords\"\n",
    "\n",
    "if not os.path.exists(DATASET_DIR):\n",
    "    os.mkdir(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch(file, image_size=96):\n",
    "    # perform the data augmentation strategy used in the project\n",
    "    img = cv2.imread(file, 1)\n",
    "    \n",
    "    if img.shape != (50,50,3):\n",
    "        return None\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img,(image_size, image_size))\n",
    "    # extract L* and a* from LAB and H and S from HSV\n",
    "    L,A,_ = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2LAB))\n",
    "    H,S,_ = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))\n",
    "    \n",
    "    if img is not None:\n",
    "        # perform CHAHE normalization\n",
    "        clahe = cv2.createCLAHE(clipLimit=5, tileGridSize=(16,16))\n",
    "        planes = cv2.split(img)\n",
    "        for i in range(0,3):\n",
    "            planes[i] =clahe.apply(planes[i])\n",
    "        img = cv2.merge(planes)\n",
    "        \n",
    "        # apply a Gaussian blue\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "        # merge the final feature vector\n",
    "        img = cv2.merge([img,L,H,S,A])\n",
    "        img = np.asarray(img)\n",
    "                    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_patch\n",
    "fig, axs = plt.subplots(nrows=3, ncols=5, constrained_layout=False, figsize=(12,6))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    img = get_patch(training_files[i])\n",
    "    \n",
    "    ax.imshow(img[...,:3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_name, files, training):\n",
    "    n_positives = 0\n",
    "    n_negatives = 0\n",
    "    stop1 = False\n",
    "    stop2 = False\n",
    "    skip = 0\n",
    "    TRAIN_FILE = dataset_name + '.tfrecords'\n",
    "    \n",
    "    with TFRecordManager(os.path.join(DATASET_DIR, TRAIN_FILE)) as writer:\n",
    "        \n",
    "        for file in files:\n",
    "            class_id = int(file[-5])\n",
    "            \n",
    "            if class_id == 1: \n",
    "                n_positives += 1\n",
    "            else:\n",
    "                if training == True:\n",
    "                    prob = np.random.rand()\n",
    "                    # ensure the ration of positives to negative samples are 1:1\n",
    "                    if prob >= 0.3864:\n",
    "                        continue\n",
    "                n_negatives += 1\n",
    "                \n",
    "            patch = get_patch(file)\n",
    "    \n",
    "            if patch is None:\n",
    "                skip += 1\n",
    "                continue\n",
    "            \n",
    "            example = get_tf_feature(patch, class_id)\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "        print(f\"Process has finished with a total of {n_negatives} negatives and {n_positives} positive patches.\")\n",
    "        print(f\"Skipped {skip} images for UNEXPECTED patch shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each bag contains 50% of the original training data\n",
    "subsample = 0.5\n",
    "\n",
    "# create the 3 training bags as tfrecord files\n",
    "for i in range(3):\n",
    "    bag_train_files = resample(training_files, replace=True, n_samples=int(subsample*len(training_files)))\n",
    "    create_dataset('train_bag_' + str(i), bag_train_files, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the validation tfrecord set\n",
    "create_dataset('val', val_files, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the testing tfrecord set\n",
    "create_dataset('test', test_files, training=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asap",
   "language": "python",
   "name": "asap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
